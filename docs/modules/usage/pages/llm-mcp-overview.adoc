//
// Copyright 2025 The Apache Software Foundation
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

= LLMs and MCPs Overview
ifndef::env-site[:toc:]

A brief introduction to Large Language Models (LLMs) and the Model Context Protocol (MCP) for Maven support workflows.

== What are LLMs?

Large Language Models are AI systems trained on vast amounts of text data.
They can understand and generate human-like text, making them useful for:

* Answering questions about code and documentation
* Analyzing discussions and summarizing decisions
* Helping navigate complex codebases
* Assisting with code reviews and improvements

Examples of LLM clients include Claude Code (CLI), Claude Desktop, and various IDE integrations.

== What is MCP?

The **Model Context Protocol (MCP)** is an open standard that enables LLMs to access external tools and data sources.
Think of it as a way to give LLMs "hands" to interact with real systems.

[source,text]
----
┌─────────────────┐     MCP      ┌─────────────────┐
│   LLM Client    │◄────────────►│   MCP Server    │
│ (Claude Code)   │   Protocol   │  (mail-mcp)     │
└─────────────────┘              └─────────────────┘
                                         │
                                         ▼
                                 ┌─────────────────┐
                                 │  Data Source    │
                                 │ (Mail Archive)  │
                                 └─────────────────┘
----

=== Key Benefits

Standardized Interface::
MCP provides a consistent way for LLMs to interact with different tools.
One protocol, many integrations.

Local Execution::
MCP servers run locally, keeping your data and credentials secure.
The LLM never directly accesses your systems.

Composable::
Multiple MCP servers can be combined, allowing cross-referencing between data sources (e.g., finding a mail thread that discusses a GitHub issue).

== Maven MCPs

This project provides MCP servers for Maven-related data:

[cols="1,3"]
|===
|MCP Server |Purpose

|**Mail MCP**
|Access Apache Maven mailing list archives (dev@ and users@)

|**GitHub MCP**
|Access Maven repositories, issues, and pull requests on GitHub

|**Atlassian MCP**
|Access Apache Confluence documentation and Jira (legacy issues)
|===

== How It Works

. **LLM Client** (e.g., Claude Code) connects to one or more MCP servers
. **User asks a question** about Maven
. **LLM uses MCP tools** to search mail archives, GitHub issues, or Confluence
. **LLM synthesizes** the information and provides a comprehensive answer

For example, asking "What was the decision about Maven 4 module support?" might:

. Search mail archives for "Maven 4 module" discussions
. Find referenced GitHub issues or PRs
. Cross-reference Confluence documentation
. Summarize the decision and its rationale

== Next Steps

* xref:claude-code-setup.adoc[Install Claude Code] as your LLM client
* xref:mcp-setup.adoc[Set up MCP servers] (Docker-based)
